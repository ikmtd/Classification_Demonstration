{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikmtd/Classification_Demonstration/blob/main/Classification_Demonstration_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqoBPqVFV6Ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af437745-f1ce-451c-c064-e2c8cf2528a7"
      },
      "source": [
        "#Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFPJX6NQWBQe"
      },
      "source": [
        "#import Modules\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets, models\n",
        "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import csv"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIxNQBWzIZPn",
        "outputId": "bbea4df7-df99-4bcb-9f17-1bd288c3a6f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ã€€Move to the location where the Classification_Demonstration folder is saved.\n",
        "cd '/content/drive/My Drive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u99ja5olm3sr",
        "outputId": "9c110555-5844-4c35-c24e-94ba276e86a0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIXFFhTDxScw"
      },
      "source": [
        "#test dataset\n",
        "data_dir = 'Classification_Demonstration/data/test_data/'\n",
        "#wt -/- TK6\n",
        "wt_dir = data_dir + 'wt/'\n",
        "#ctf18 -/- TK6\n",
        "ctf18_dir = data_dir + 'ctf18/'\n",
        "\n",
        "#resize\n",
        "size = (224, 224)\n",
        "\n",
        "data_transforms = {\n",
        "        'test' : transforms.Compose([\n",
        "          transforms.Resize(size),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ]),\n",
        "\n",
        "        'display' : transforms.Compose([\n",
        "          transforms.Resize(size),\n",
        "          ]),\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "#test dataset\n",
        "wt_dataset = datasets.ImageFolder(wt_dir, transform=data_transforms['test'])\n",
        "ctf18_dataset = datasets.ImageFolder(ctf18_dir, transform=data_transforms['test'])\n",
        "\n",
        "#test dataset for display\n",
        "wt_dataset_display = datasets.ImageFolder(wt_dir, transform=data_transforms['display'])\n",
        "ctf18_dataset_display = datasets.ImageFolder(ctf18_dir, transform=data_transforms['display'])\n",
        "\n",
        "dataloaders = {\n",
        "        'wt' : torch.utils.data.DataLoader(wt_dataset, batch_size= 64),\n",
        "        'ctf18' : torch.utils.data.DataLoader(ctf18_dataset, batch_size= 64)\n",
        "}"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHW2fFaINCuA",
        "outputId": "b5883683-cd46-4430-d17e-01c77efbcef1"
      },
      "source": [
        "#Correspondence between labels and indexes\n",
        "# typeA: 0, typeB: 1, typeC: 2 \n",
        "print(wt_dataset.class_to_idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'b': 1, 'c': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting predicted number of images in dataset\n",
        "\n",
        "def pred_count(ypreds, class_num):\n",
        "  count_len = []\n",
        "  ypreds = ypreds.to('cpu').detach().numpy().copy()\n",
        "  ypreds = ypreds.tolist()\n",
        "  for i in range(class_num):\n",
        "    count = ypreds.count(i)\n",
        "    count_len.append(count)\n",
        "  return count_len"
      ],
      "metadata": {
        "id": "gVnOyZipuIit"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSVphz0HPmbI"
      },
      "source": [
        "# Define Test Network\n",
        "def test_net(csv_name, net, test_loader, device=\"cpu\"):\n",
        "  net.eval()\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "  #class number\n",
        "  class_num = 3\n",
        "  for x, y in test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    with torch.no_grad():\n",
        "      y_net = net(x)\n",
        "      _, y_pred = nn.functional.softmax(y_net, dim=1).max(1)\n",
        "    ys.append(y)\n",
        "    ypreds.append(y_pred)\n",
        "  # ys : Labels for all test data.\n",
        "  ys = torch.cat(ys)\n",
        "  # ypreds : Prediction results for all test data.\n",
        "  ypreds = torch.cat(ypreds)\n",
        "  acc = (ys == ypreds).float().sum() / len(ys)\n",
        "  pred_sum = pred_count(ypreds, class_num)\n",
        "  ypreds = pd.DataFrame(ypreds.to(\"cpu\"))\n",
        "  ypreds.to_csv('Classification_Demonstration/results/'+str(csv_name)+'.csv', index=False, header=False)\n",
        "  data_num = sum(pred_sum)\n",
        "  pred_percent = (round(pred_sum[0]/data_num, 2), round(pred_sum[1]/data_num, 2), round(pred_sum[2]/data_num, 2))\n",
        "  return [acc.item(), pred_percent]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Both ResNet and SqueezeNet can be selected from 1~30. \n",
        "net_num = 1"
      ],
      "metadata": {
        "id": "wZ5ZcL6_wCPF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SqueezeNet\n",
        "squeezenet = models.squeezenet1_1(pretrained=True)\n",
        "for param in squeezenet.parameters():\n",
        "    param.requires_grad = False\n",
        "squeezenet.classifier[1] = nn.Conv2d(512, 3, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "squeezenet.load_state_dict(torch.load('Classification_Demonstration/models/SqueezeNet/SqueezeNet_' + str(net_num) + '.pth'))\n",
        "squeezenet.to(\"cuda:0\")\n",
        "\n",
        "# wt cells chromosomes prediction\n",
        "sq_acc_wt, sq_pred_wt = (test_net('wt_SqueezeNet', squeezenet, dataloaders['wt'], device = \"cuda:0\")) # The first argument of the test_net() is csv file name.\n",
        "print( \"wt\")\n",
        "print(\"Concordande Rates : \", str(sq_acc_wt))\n",
        "print(\"Predicted percentage\")\n",
        "print('typeA', sq_pred_wt[0], 'typeB', sq_pred_wt[1], 'typeC', sq_pred_wt[2])\n",
        "print()\n",
        "\n",
        "# ctf-18 cells chromosomes prediction\n",
        "sq_acc_ctf18, sq_pred_ctf18 = (test_net('ctf18_SqueezeNet', squeezenet, dataloaders['ctf18'], device = \"cuda:0\"))\n",
        "print( \"ctf18\")\n",
        "print(\"Concordande Rates : \", str(sq_acc_ctf18))\n",
        "print(\"Predicted percentage\")\n",
        "print('typeA', sq_pred_ctf18[0], 'typeB', sq_pred_ctf18[1], 'typeC', sq_pred_ctf18[2])"
      ],
      "metadata": {
        "id": "cto_NrmtSyUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet-18\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "for p in resnet.parameters():\n",
        "   p.requires_grad=False\n",
        "fc_input_dim  = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(fc_input_dim, 3)\n",
        "resnet.to(\"cuda:0\")\n",
        "\n",
        "resnet.load_state_dict(torch.load(path +  'Classification_Demonstration/models/ResNet-18/ResNet18_' + str(net_num) + '.pth'))\n",
        "resnet.to(\"cuda:0\")\n",
        "\n",
        "# wt cells chromosomes prediction\n",
        "res_acc_wt, res_pred_wt = (test_net('wt_ResNet-18', resnet, dataloaders['wt'], device = \"cuda:0\")) # The first argument of the test_net() is csv file name.\n",
        "print( \"wt\")\n",
        "print(\"Concordande Rates : \", str(res_acc_wt))\n",
        "print(\"Predicted percentage\")\n",
        "print('typeA', res_pred_wt[0], 'typeB', res_pred_wt[1], 'typeC', res_pred_wt[2])\n",
        "print()\n",
        "\n",
        "# ctf-18 cells chromosomes prediction\n",
        "res_acc_ctf18, res_pred_ctf18 = (test_net('ctf18_ResNet-18', resnet, dataloaders['ctf18'], device = \"cuda:0\"))\n",
        "print( \"ctf18\")\n",
        "print(\"Concordande Rates : \", str(res_acc_ctf18))\n",
        "print(\"Predicted percentage\")\n",
        "print('typeA', res_pred_ctf18[0], 'typeB', res_pred_ctf18[1], 'typeC', res_pred_ctf18[2])"
      ],
      "metadata": {
        "id": "cM_pqYh2o_nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The following codes can be executed to match the image, label, and prediction results."
      ],
      "metadata": {
        "id": "rOf2Csj3Ow75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idx_to_class(num):\n",
        "  if num == 0:\n",
        "    return 'typeA'\n",
        "  elif num == 1:\n",
        "    return 'typeB'\n",
        "  elif num == 2:\n",
        "    return 'typeC'"
      ],
      "metadata": {
        "id": "jUk42PTJ6XwS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the name to whatever you decide in csv_filename.\n",
        "csv_filename = 'wt_SqueezeNet.csv'"
      ],
      "metadata": {
        "id": "wOPhfd_iPc-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class = []\n",
        "with open('Classification_Demonstration/results/' + str(csv_filename) + '.csv') as f:\n",
        "  reader = csv.reader(f)\n",
        "\n",
        "  for row in reader:\n",
        "      pred_class.append(int(row[0]))\n",
        "\n",
        "# Note that pred_class is a large value. You can adjust it to any number. \n",
        "for i in range(len(pred_class)):\n",
        "  image, label = wt_dataset_display[i]\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "  print('label : ', idx_to_class(label), 'predict : ', idx_to_class(pred_class[i]))"
      ],
      "metadata": {
        "id": "gDBADnng3OHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-oog6e3tFs7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}